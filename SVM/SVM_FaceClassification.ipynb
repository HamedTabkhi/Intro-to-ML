{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamedTabkhi/Intro-to-ML/blob/main/SVM_FaceClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de380d3d-6d20-422d-a800-2f437aec9d80",
      "metadata": {
        "id": "de380d3d-6d20-422d-a800-2f437aec9d80"
      },
      "outputs": [],
      "source": [
        "#As an example of support vector machines in action, let's take a look at the facial recognition problem.\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "faces = fetch_lfw_people(min_faces_per_person=60)\n",
        "print(faces.target_names)\n",
        "print(faces.images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0503639e-9551-411e-b9f1-2eded61acd9b",
      "metadata": {
        "id": "0503639e-9551-411e-b9f1-2eded61acd9b"
      },
      "outputs": [],
      "source": [
        "#Let's plot a few of these faces to see what we're working with:\n",
        "fig, ax = plt.subplots(3, 5)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(faces.images[i], cmap='bone')\n",
        "    axi.set(xticks=[], yticks=[],\n",
        "            xlabel=faces.target_names[faces.target[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adf57ad6-d5c3-4af9-ad07-7f2c1cb23d15",
      "metadata": {
        "id": "adf57ad6-d5c3-4af9-ad07-7f2c1cb23d15"
      },
      "outputs": [],
      "source": [
        "#Each image contains [62Ã—47] or nearly 3,000 pixels.\n",
        "#We could proceed by simply using each pixel value as a feature,\n",
        "#but often it is more effective to use some sort of preprocessor to extract more meaningful features;\n",
        "#here we will use a principal component analysis to extract 150 fundamental components.\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA as RandomizedPCA\n",
        "pca = RandomizedPCA(n_components=150, whiten=True, random_state=42)\n",
        "svc = SVC(kernel='rbf', class_weight='balanced') #radial basis function kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32658f97-b9c8-4f86-957d-452e1f2302d3",
      "metadata": {
        "id": "32658f97-b9c8-4f86-957d-452e1f2302d3"
      },
      "outputs": [],
      "source": [
        "#For the sake of testing our classifier output, we will split the data into a training and testing set:\n",
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target,\n",
        "                                                random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c04738e4-f478-44f3-af84-fc70f37f6a8a",
      "metadata": {
        "id": "c04738e4-f478-44f3-af84-fc70f37f6a8a"
      },
      "outputs": [],
      "source": [
        "#Finally, we can use a grid search cross-validation to explore combinations of parameters.\n",
        "#Here we will adjust C (which controls the margin hardness)\n",
        "#We also explore gamma (which controls the size of the radial basis function kernel)\n",
        "#and determine the best model:\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "svc = SVC(kernel='rbf', class_weight='balanced')\n",
        "model = make_pipeline(pca, svc)\n",
        "param_grid = {'svc__C': [1, 5, 10, 50],\n",
        "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
        "grid = GridSearchCV(model, param_grid) #GridSearchCV determines the best model\n",
        "\n",
        "%time grid.fit(Xtrain, ytrain)\n",
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bd47445-4e2a-4870-811f-c4f5c8be65a2",
      "metadata": {
        "id": "6bd47445-4e2a-4870-811f-c4f5c8be65a2"
      },
      "outputs": [],
      "source": [
        "#The optimal values fall toward the middle of our grid;\n",
        "#if they fell at the edges, we would want to expand the grid to make sure we have found the true optimum.\n",
        "#Now with this cross-validated model, we can predict the labels for the test data\n",
        "model = grid.best_estimator_\n",
        "yfit = model.predict(Xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff348e69-f702-4b74-b15b-4ea6473cf89d",
      "metadata": {
        "id": "ff348e69-f702-4b74-b15b-4ea6473cf89d"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(4, 6)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n",
        "    axi.set(xticks=[], yticks=[])\n",
        "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n",
        "                   color='black' if yfit[i] == ytest[i] else 'red')\n",
        "fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27f658c9-db94-440f-81fc-5faaa9d9a76c",
      "metadata": {
        "id": "27f658c9-db94-440f-81fc-5faaa9d9a76c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(ytest, yfit,\n",
        "                            target_names=faces.target_names))\n",
        "\n",
        "#F1 score - F1 Score is the weighted average of Precision and Recall.\n",
        "#Therefore, this score takes both false positives and false negatives into account.\n",
        "#F1 is usually more useful than accuracy, especially if you have an uneven class distribution.\n",
        "#Accuracy works best if false positives and false negatives have similar cost.\n",
        "#F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
        "#A macro-average will compute the metric independently for each class and then take the average\n",
        "#Macro-average treats all classes equally,\n",
        "#A micro-average will aggregate the contributions of all classes to compute the average metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d9bf261-ca4e-4d95-a012-632535816928",
      "metadata": {
        "id": "6d9bf261-ca4e-4d95-a012-632535816928"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "mat = confusion_matrix(ytest, yfit)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=faces.target_names,\n",
        "            yticklabels=faces.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2ef29da-c0dc-458d-969a-64619758461f",
      "metadata": {
        "id": "b2ef29da-c0dc-458d-969a-64619758461f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
